{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ixj9L-cOyho"
   },
   "source": [
    "![heading2](https://user-images.githubusercontent.com/72619946/98711135-3a717c00-234a-11eb-91f5-a218f35de775.jpeg)\n",
    "# WELCOME! \n",
    "\n",
    "### This is the coding playground for the third D(3) Digitial Deep Dive \n",
    "### Novermber 3rd 2020\n",
    "Questions? Feel free to reach out to Christian Lynn\n",
    "christian_lynn@baxter.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeKJyR1lyEMf"
   },
   "outputs": [],
   "source": [
    "#Usual Imports\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import datetime as dt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting default plot shape\n",
    "plt.tight_layout(False)\n",
    "plt.rcParams.update({'text.color' : \"r\",\n",
    "                     'axes.labelcolor' : \"r\"})\n",
    "plt.rcParams['xtick.color'] = 'r'\n",
    "plt.rcParams['ytick.color'] = 'r'\n",
    "sns.set(rc={'figure.figsize':(10,8)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufTUtp8YJzxe"
   },
   "source": [
    "## **Starting this Analysis by reading in 2 subsets of data:**\n",
    "the data collected by the end of session 2, and the full raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "3ECtNs-UyEMp",
    "outputId": "8a9a0e52-d7e8-444d-abff-25c9194bd63c"
   },
   "outputs": [],
   "source": [
    "#RAW DATA HERE\n",
    "url = 'https://raw.githubusercontent.com/ChristianRLynn/DataSets/main/train.csv'\n",
    "raw = pd.read_csv(url, error_bad_lines=False); raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "iVsIexvoyEMw",
    "outputId": "fd326be2-67ca-47a4-da03-d1720946e6b5"
   },
   "outputs": [],
   "source": [
    "#EDITED DATA LETS SEE HOW WE DID\n",
    "url2 = 'https://raw.githubusercontent.com/ChristianRLynn/DataSets/main/new_data_intermediate_V2.csv'\n",
    "part2_data = pd.read_csv(url2, error_bad_lines=False); part2_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgfn4mn6U6YP"
   },
   "source": [
    "# The two datasets are below, and using the .shape funtion I can see how big each dataset is in the shape (rows,columns). \n",
    "Notice that part2_data is actually bigger than the raw dataset, those are our created features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "z2ADxYDvU8vc",
    "outputId": "14e85a0a-9d14-481b-8539-f003d3390a2a"
   },
   "outputs": [],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5HbznB4SU8zH",
    "outputId": "dac0066a-bedf-46ba-a2ce-123f458c1fd9"
   },
   "outputs": [],
   "source": [
    "part2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "_N_wNCRQyEM2",
    "outputId": "43b88a4e-d4b6-4532-9621-055f8e0376af"
   },
   "outputs": [],
   "source": [
    "#Looking at column data, super helpfull to see our features:\n",
    "raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great function call is describe(). This gives count, mean, std, min, and...\n",
    "the two middle quartiles (think boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "hpxqxOMxqjvy",
    "outputId": "35891c93-2cc8-4f9b-91aa-741b76ba901c"
   },
   "outputs": [],
   "source": [
    "raw.describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO0CD54aWX0D"
   },
   "source": [
    "Another really interesting call is value_counts()\n",
    "\n",
    "This call will print out whatever column you send to it with the counts\n",
    "for all of the unieque values within it. \n",
    "\n",
    "So unlike above, you have the prevelance of each value, not just what each column contains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "eIoZ3AXjyENC",
    "outputId": "dcb67b4e-21dd-4c0c-fe59-f8f4935e172f"
   },
   "outputs": [],
   "source": [
    "raw['MSZoning'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AZmS3K4Xf4b"
   },
   "source": [
    "Very similar to what I like to do with a pivot table, but is so much quicker and can be done on multiple columns quite easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5C6O0jc2yEM8",
    "outputId": "64f41fec-2dfc-4329-83e4-beadbe961b23"
   },
   "outputs": [],
   "source": [
    "for colu in raw:                             #grab column out columns from the dataset. Will cycle through them, but will reference each one as \"colu\" in turn\n",
    "    if len(raw[f\"{colu}\"].unique())<15:   \n",
    "      print(f'Column Name: {colu}')           # printing out the column name\n",
    "      print(f\"Unique Values: {raw[f'{colu}'].unique()}\")    #printing out all the unieque values within raw for each column\n",
    "      print(f\"Value Counts for each variable: \\n{raw[f'{colu}'].value_counts()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I30cXDDm8uul"
   },
   "source": [
    "I can also filter columns much more easily than in excel, I can either omit them by using a data.drop(columns=\"what\",\"ever\",\"we\",\"dont\",want\")\n",
    "or by creating a list of the columns we do want to keep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7NDFOn6yENH"
   },
   "outputs": [],
   "source": [
    "colers=['MSZoning', 'LotFrontage', 'LotArea',\n",
    "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "       'ExterQual', 'ExterCond', 'BsmtFinSF1', 'TotalBsmtSF',\n",
    "       '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'FullBath', 'HalfBath',\n",
    "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'GarageCars',\n",
    "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "       'ScreenPorch', 'YrSold', 'SaleType', 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08PxUDZzyENM"
   },
   "outputs": [],
   "source": [
    "raw_small=raw[colers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "_NyhT2yKyENU",
    "outputId": "6bd651dd-f7d0-474b-c9ab-a81334c54bae"
   },
   "outputs": [],
   "source": [
    "raw_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JnUlncFa07f"
   },
   "source": [
    "Let's create one of our favorite columns that we had created, tot_porch.\n",
    "It is easy to do additions and create new columns: simply create the new column first, then insert the combination/calculations of columns that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "cTmuZAeXyEN-",
    "outputId": "0e5b1cc1-9707-4771-bcad-8914327b1b5f"
   },
   "outputs": [],
   "source": [
    "raw_small['tot_porch']=raw_small['EnclosedPorch']+raw_small['3SsnPorch']+raw_small['ScreenPorch'];\n",
    "raw_small.drop(columns=['EnclosedPorch', '3SsnPorch','ScreenPorch'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj1ObHPYdw-N"
   },
   "source": [
    "Now, to recreate the correlation chart that we created in excel, \n",
    "that allowed us to drop useless-ish columns before and focus on what mattered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "0RL4kM5kyEOL",
    "outputId": "03d5f5fe-b9c8-4fe1-cb5d-499d2f9bfbcc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfer = pd.DataFrame(part2_data[part2_data.columns])\n",
    "corr = dfer.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's filter out all the columns that show a good correlation with our target \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "YwBsqnNwkBCE",
    "outputId": "b6b5ece7-bd9a-419c-b029-9e54ad20e7a2"
   },
   "outputs": [],
   "source": [
    "correlated=pd.DataFrame(index=part2_data.index)                                #create the empty space first\n",
    "for colu in part2_data.drop(columns=['Id']):                                   #cycle through each column\n",
    "  if abs(part2_data['SalePrice'].corr(part2_data[f'{colu}'])) >=.5:            # only get columns correlated with SalePrice .5 or higher\n",
    "    print(colu)                                                                # Print and add to new dataframe \"correlated\"\n",
    "    correlated[f'{colu}']=(part2_data[f'{colu}'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What am I looking for here?\n",
    "Well, the baseline model I am using (Simple Linear Regression) attempts to combine linear combinations of variables.\n",
    "\n",
    "best_guess = intercept + weight1*variable1 + weight2*variable2 + weight3*variable3....\n",
    "\n",
    "So there are two major things we should try to think about:\n",
    "1.) How is our target variable distributed?\n",
    "2.) Are there combinations of variables that tell the same story (near perfect correlation)\n",
    "\n",
    "Lets start by looking at the data and see if we can simplify any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfer = pd.DataFrame(correlated[correlated.columns])\n",
    "corr = dfer.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the highy red areas, the quality ratings are very similar AND have high impact on the target. What one shall we pick to keep?\n",
    "\n",
    "Also, I have BOTH YearBuilt and log_yfn (years from now). What one to choose now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=correlated.drop(columns=['FullBath', 'TOT_rooms', 'YearBuilt', 'quality_mult', 'log_qual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same visualizations that we created in Excel, are done here much more easily. \n",
    "There are a multitude of things we can do to visualize data, but I want to get to modeling and talk about that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we model, just want to show how much easier it is to edit and controll graphs in Python compared to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"Neighborhood\", y=\"SalePrice\", data=raw).set_title(\"Our Old Friend the Neighborhood Boxplot\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR FIRST MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define another metric that we will look at today. \n",
    "Root Mean Squared Error is a great statistic, and it punishes outliers very harshly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VELqKxqTyEO2"
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "\n",
    "    differences = predictions - targets                       #the DIFFERENCEs.\n",
    "\n",
    "    differences_squared = differences ** 2                    #the SQUAREs of ^\n",
    "\n",
    "    mean_of_differences_squared = differences_squared.mean()  #the MEAN of ^\n",
    "\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)           #ROOT of ^\n",
    "\n",
    "    return rmse_val   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define out train and test data. One we will use to train our model on (think homework)\n",
    "the other test set (like a test with unseen answers) will be used for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2 data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(part2_data.drop(columns='SalePrice'), part2_data.SalePrice, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2 data split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(correlated.drop(columns='SalePrice'), correlated.SalePrice, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cft4sMWVyEOy"
   },
   "outputs": [],
   "source": [
    "# Raw splity, lets start here!\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(raw.drop(columns='SalePrice'), raw.SalePrice, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is how Pythjon and ScikitLearn work\n",
    "\n",
    "Model choice comes here\n",
    "\n",
    "fitting(features,target)   #Where the model trains on past data\n",
    "\n",
    "predicting(train_features/test_features)    #the model then gets to test itself \n",
    "\n",
    "scoring(test_features,test_target)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "Fym-QnXRyEPJ",
    "outputId": "d13169c0-54f5-46b5-fa96-7afda43ac54f"
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression() #defining our model\n",
    "\n",
    "#fitting the model\n",
    "reg = reg.fit(X_train_raw,y_train_raw)\n",
    "\n",
    "#Predicting both training and test sets so I can compare to reality\n",
    "pred_train = reg.predict(X_train_raw)\n",
    "pred_test = reg.predict(X_test_raw)\n",
    "\n",
    "#Scoring both the training sets and the test sets\n",
    "y_pred = reg.score(X_test_raw,y_test_raw)\n",
    "ttree = reg.score(X_train_raw, y_train_raw)\n",
    "\n",
    "#testing metrics are output here\n",
    "print(\"Training score of Regression Model\",ttree)\n",
    "print(\"Testing Score of Regression Model\",y_pred)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_train,y_train_raw)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_test,y_test_raw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happened here?? We did not check our data before we began modeling.\n",
    "\n",
    "Right now our model is responding to catagorical values still in the raw dataset (MSZoning here).\n",
    "\n",
    "We also need to check for NaN values (empty), values that are extreme (think infinite), and any other errors we want!\n",
    "\n",
    "Excel is not always good at telling us where or when we have missing values, sometimes in numerical columns it will simply just add a 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_na = (raw.isnull().sum() / len(raw)) * 100 #creating percentages of missing values (missing/total * 100)\n",
    "raw_data_na = raw_data_na.drop(raw_data_na[raw_data_na == 0].index).sort_values(ascending=False)[:40] #Focus\n",
    "missing_data_raw = pd.DataFrame({'Missing Ratio in Raw' :raw_data_na})\n",
    "missing_data_raw.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To test our our Excel-based feature cleaning and engineering, lets see if we can build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "ATH5Z2os16fO",
    "outputId": "21bd7b9b-fbd9-433f-ac41-2025ac4d6234"
   },
   "outputs": [],
   "source": [
    "data_na = (part2_data.isnull().sum() / len(raw)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:40]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated[correlated.YearBuilt.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = 100-(np.isfinite(part2_data).sum() / len(raw)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:40]\n",
    "missing_data = pd.DataFrame({'Infinate Ratio' :data_na})\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets give it a shot with our cleaned dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model we hav already defined\n",
    "reg = reg.fit(X_train,y_train)\n",
    "\n",
    "#Predicting both training and test sets so I can compare to reality\n",
    "pred_train = reg.predict(X_train)\n",
    "pred_test = reg.predict(X_test)\n",
    "\n",
    "#Scoring both the training sets and the test sets\n",
    "y_pred = reg.score(X_test,y_test)\n",
    "ttree = reg.score(X_train, y_train)\n",
    "\n",
    "#testing metrics are output here\n",
    "#default score for regression model is R^2\n",
    "print(\"Training score of part2 Regression Model\",ttree)\n",
    "print(\"Testing Score of part2 Regression Model\",y_pred)\n",
    "\n",
    "#Mean Absolute Error is a great metric, it is the average deviation between prediction and reality\n",
    "print(f'\\nTraining MAE of part2 model: {mae(pred_train,y_train)}')\n",
    "print(f'Testing MAE of part2 model: {mae(pred_test,y_test)}')\n",
    "\n",
    "#RMSE - Root Mean Squared error, another typical metic, this one has a squared term to penalize big misses\n",
    "print(f'\\nTraining RMSE of part2 model: {rmse(pred_train,y_train)}')\n",
    "print(f'Testing RMSE of part2 model: {rmse(pred_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With our much smaller dataset of 17 features\n",
    "reg2 = LinearRegression() #redefining our model\n",
    "reg2 = reg.fit(X_train_s,y_train_s)\n",
    "y_pred_s = reg2.score(X_test_s,y_test_s)\n",
    "ttree_s = reg2.score(X_train_s, y_train_s)\n",
    "pred_train_s = reg.predict(X_train_s)\n",
    "pred_test_s = reg.predict(X_test_s)\n",
    "print(\"Training score of small Regression Model\",ttree_s)\n",
    "print(\"Testing Score of small Regression Model\",y_pred_s)\n",
    "print(f'\\nTraining RMSE of small model: {rmse(pred_train_s,y_train_s)}')\n",
    "print(f'Testing RMSE of small model: {rmse(pred_test_s,y_test_s)}')\n",
    "print(f'\\nTraining MAE of small: {mae(pred_train_s,y_train_s)}')\n",
    "print(f'Testing MAE of small model: {mae(pred_test_s,y_test_s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW! We explained 84% of the variation in the dataset! But we still have a long way to go.\n",
    "\n",
    "We are going to revisit this, for if we can explain the same amount of variation in the data with a much smaller model,\n",
    "we can more easily deploy it, explain it, and make it faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3FPPjJdBDm2"
   },
   "source": [
    "# Here were my first thoughts of transforming the Raw dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take that first model as a baseline, if we can't beat that easily, maybe we stop there!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "lgJpPLgwyEPj",
    "outputId": "991cde6c-14b1-4185-bcca-219c41f1d493"
   },
   "outputs": [],
   "source": [
    "#very robust model, able to handle outliers, typically a great place to start\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "#fitting the model to the data\n",
    "forest = forest.fit(X_train,y_train)\n",
    "#Score the results\n",
    "train_score_forest = forest.score(X_train, y_train)\n",
    "test_score_forest = forest.score(X_test,y_test)\n",
    "\n",
    "pred_train_forest = forest.predict(X_train)\n",
    "pred_test_forest = forest.predict(X_test)\n",
    "print(\"Training score of RF Model\",train_score_forest)\n",
    "print(\"Testing Score of RF Model\",test_score_forest)\n",
    "print(f'\\nTraining RMSE of RF model: {rmse(pred_train_forest,y_train)}')\n",
    "print(f'Testing RMSE of RF model: {rmse(pred_test_forest,y_test)}')\n",
    "print(f'\\nTraining MAE of RF model: {mae(pred_train_forest,y_train)}')\n",
    "print(f'Testing MAE of RF model: {mae(pred_test_forest,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MbjW9TbyEPc"
   },
   "source": [
    "Let's not immediately start throwing models at the data, for although we have improved, we have not done much other than throwing fancy algos at the data.\n",
    "\n",
    "This will be our new baseline, and we need to work hard to beat this!\n",
    "\n",
    "### Starting with the RAW dataset, what do we need to fix or what can we improve?\n",
    "\n",
    "Maybe let's look for outliers, and there are many ways to do this with statistics, so I will not bore you here with them.\n",
    "\n",
    "Revisiting week 2 leaves us with this one outler set, how do we visualize and remove the value in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "8pTa3Hpw166l",
    "outputId": "83b183ed-778b-47fc-bf6a-69a949a58102"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = raw['GrLivArea'], y = raw['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=13)\n",
    "plt.xlabel('GrLivArea', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQG13Npj17SU"
   },
   "outputs": [],
   "source": [
    "train = raw.drop(raw[(raw['GrLivArea']>4000) & (raw['SalePrice']<300000)].index) \n",
    "#very similar to an excel foruma here, but in the same \"new_thing = data[filter1]\" notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUlXHo6b9O-T"
   },
   "outputs": [],
   "source": [
    "full_data_clean=train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to clean data, and to get python code to do what you want. \n",
    "To fill empty values, the .fillna() call is your best friend.\n",
    "You can fill with a constant, means, or medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMPNrid84zlS"
   },
   "outputs": [],
   "source": [
    "#All of these missing values refer to certain columns where features are not present. \n",
    "#Missing means 0 here. \n",
    "full_data_clean[\"PoolQC\"] = full_data_clean[\"PoolQC\"].fillna(0)\n",
    "full_data_clean[\"MiscFeature\"] = full_data_clean[\"MiscFeature\"].fillna(0)\n",
    "full_data_clean[\"Alley\"] = full_data_clean[\"Alley\"].fillna(0)\n",
    "full_data_clean[\"Fence\"] = full_data_clean[\"Fence\"].fillna(0)\n",
    "full_data_clean[\"FireplaceQu\"] = full_data_clean[\"FireplaceQu\"].fillna(0)\n",
    "full_data_clean[\"MasVnrArea\"] = full_data_clean[\"MasVnrArea\"].fillna(0)\n",
    "full_data_clean[\"Electrical\"] = full_data_clean[\"Electrical\"].fillna(0)\n",
    "full_data_clean[\"LotFrontage\"] = full_data_clean[\"LotFrontage\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have large segments of data, you can also use a loop to move through all the columns you want.\n",
    "Below are all the basement and garage metrics (both where NA means 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIn661A713T7"
   },
   "outputs": [],
   "source": [
    "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', \n",
    "            'BsmtFullBath', 'BsmtHalfBath','GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    full_data_clean[col] = full_data_clean[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These variables are catagorical, so we can fill them with a different label\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    full_data_clean[col] = full_data_clean[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "    full_data_clean[col] = full_data_clean[col].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_clean[\"MasVnrType\"] = full_data_clean[\"MasVnrType\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mwqn983g-Rx7"
   },
   "source": [
    "But What about values that have no difinitive zero value in the data?\n",
    "\n",
    "MSZoning and Electrical should all have values but do not.\n",
    "\n",
    "\n",
    "This is more similar to a problem we see in the real world, most of Baxter data is in this shape,\n",
    "\n",
    "and what we choose to do here can have large influences on the outcome of any model\n",
    "\n",
    "Lets look at MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "lIyf2q9y-Ntb",
    "outputId": "edb12bb1-2dc0-41b9-a604-169cce76407f"
   },
   "outputs": [],
   "source": [
    "full_data_clean['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHsi86K--OgP"
   },
   "outputs": [],
   "source": [
    "full_data_clean['MSZoning'] = full_data_clean['MSZoning'].fillna('RL') #Filling with Meaian data, easily done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "W4PD3EltBBqU",
    "outputId": "80c8895b-6c69-4420-9748-84edcf387600"
   },
   "outputs": [],
   "source": [
    "full_data_clean['Electrical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzeXm-du9Gjk"
   },
   "outputs": [],
   "source": [
    "full_data_clean['Electrical'] = full_data_clean['Electrical'].fillna('SBrkr') #same here too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there other fancy options? \n",
    "\n",
    "Yes, but for the percentage of missing data here (small), and the impact it will have being somewhat simplified (small)\n",
    "\n",
    "We can take the easy route here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about all of the columns that are not as easily handled?\n",
    "I have spoken before about dummy and one-hot encoding. Lets look really quicky at Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QiBbcAb-0kjW"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(full_data_clean[c].values)) \n",
    "    full_data_clean[c] = lbl.transform(list(full_data_clean[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(full_data_clean.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are Many Ways to Clean this Dataset:\n",
    "### I chose to code a bit more, but be able to repeatably create good data down the line\n",
    "\n",
    "### We want calculations that can handle problems and mistakes better, I have accounted for misspelling all below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "iOVtBzbTBhip",
    "outputId": "08711d84-910e-4478-b077-8f008e880205"
   },
   "outputs": [],
   "source": [
    "#we can look at features that are non-numerical first\n",
    "train.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk0VfBKHyEQM"
   },
   "outputs": [],
   "source": [
    "#fill the columns with zeros or nones that are easy\n",
    "train['GarageYrBlt']=train['GarageYrBlt'].fillna(0)\n",
    "train['MasVnrArea']=train['MasVnrArea'].fillna(0)\n",
    "train['LotFrontage']=train['LotFrontage'].fillna(0)\n",
    "train['MasVnrType']=train['MasVnrType'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cbx-aZDZyEQP"
   },
   "outputs": [],
   "source": [
    "#The APPLY function is super fast in python, therefore these calls go through the dataset row by row but much faster than a loop would\n",
    "train['Alley']=train['Alley'].apply(lambda x: 1 if x!=0 else 0)\n",
    "train['LotShape']=train['LotShape'].apply(lambda x: 1 if x=='Reg' or x=='IR1' else 0)\n",
    "train['LandContour']=train['LandContour'].apply(lambda x: 1 if x=='Lvl' else 0)\n",
    "train['Utilities']=train['Utilities'].apply(lambda x: 1 if x=='AllPub' or x=='NoSewr' else 0)\n",
    "train['LotConfig']=train['LotConfig'].apply(lambda x: 1 if x=='Inside' or x=='CulDSac' else 0)\n",
    "train['LotConfig']=train['LotConfig'].apply(lambda x: 1 if x=='Inside' or x=='CulDSac' else 0)\n",
    "train['LandSlope']=train['LandSlope'].apply(lambda x: 1 if x=='Gtl' else 0)\n",
    "train['ExterQual']=train['ExterQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "train['ExterCond']=train['ExterCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "train['BsmtQual']=train['BsmtQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['BsmtCond']=train['BsmtCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['BsmtExposure']=train['BsmtExposure'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['BsmtFinType1']=train['BsmtFinType1'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "train['BsmtFinType2']=train['BsmtFinType2'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "train['HeatingQC']=train['HeatingQC'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['CentralAir']=train['CentralAir'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "train['KitchenQual']=train['KitchenQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "train['Functional']=train['Functional'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "train['FireplaceQu']=train['FireplaceQu'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['GarageFinish']=train['GarageFinish'].apply(lambda x: 3 if x=='Fin' else (2 if x=='RFn' else (1 if x=='Unf' else 0)))\n",
    "train['GarageQual']=train['GarageQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['GarageCond']=train['GarageCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['PavedDrive']=train['PavedDrive'].apply(lambda x: 1 if x=='Y' or x=='P' else 0)\n",
    "train['PoolQC']=train['PoolQC'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "train['Fence']=train['Fence'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "\n",
    "#we can even create new features here\n",
    "train['TOT_bath']=train['FullBath']+(.5*train['HalfBath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating One-Hot-Encodings for catagorical columns\n",
    "# Then deleting the columns in the next row using inplace\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.MSZoning)],axis=1)\n",
    "train.drop(columns=('MSZoning'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.MSSubClass)],axis=1)\n",
    "train.drop(columns=('MSSubClass'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.Neighborhood)],axis=1)\n",
    "train.drop(columns=('Neighborhood'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.BldgType)],axis=1)\n",
    "train.drop(columns=('BldgType'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.HouseStyle)],axis=1)\n",
    "train.drop(columns=('HouseStyle'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.GarageType)],axis=1)\n",
    "train.drop(columns=('GarageType'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.SaleCondition)],axis=1)\n",
    "train.drop(columns=('SaleCondition'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.SaleType)],axis=1)\n",
    "train.drop(columns=('SaleType'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.Condition1)],axis=1)\n",
    "train.drop(columns=('Condition1'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.MasVnrType)],axis=1)\n",
    "train.drop(columns=('MasVnrType'),inplace=True)\n",
    "\n",
    "train=pd.concat([train,pd.get_dummies(train.Foundation)],axis=1)\n",
    "train.drop(columns=('Foundation'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYhSZ9ZPyEQT"
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "train=train.drop(columns=['Id','Street','Condition2','RoofStyle','RoofMatl','Exterior1st','Exterior2nd', 'Heating',\n",
    "                          'Electrical','MiscFeature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "qcLuF17LyEQY",
    "outputId": "398991ce-bd12-4ffe-e8cd-e3bcf0b5ea87"
   },
   "outputs": [],
   "source": [
    "train.select_dtypes(include=['object']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvupnJEPyEQt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lets make sure we don't have any Extreme or missing values \n",
    "for column in train:\n",
    "    print(f'for column {column}') \n",
    "    print(f'\\tMAX={train[column].max()}') \n",
    "    print(f'\\tMIN={train[column].min()}') \n",
    "    print(f'\\tNAN={train[column].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "functions are small parts of code that you can define to do things. \n",
    "They work similarly to a lot of what has been done earlier (\"Iwanttodosomethingto(thisDF)\")\n",
    "You create the function, then tell it what to expect incoming, \n",
    "you do things within it, then output (or not) what you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZvYda-fyERL"
   },
   "outputs": [],
   "source": [
    "def year_transform(df, years_column):             #defining incoming dataframe and column for transformation\n",
    "    for column in years_column:                   #loop\n",
    "        df[column]=df[column]-(df[column].min()-1) #want numbers 1-> whatever with oldest houses being a large number\n",
    "        df[column]=df[column].apply(lambda x: 0 if x==0 else np.log10(x)) #we know we need to take the Log for distrobution problems\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can quickly and easlily send lots of columns in, and get them all traqnsformed in one line!\n",
    "years_column=['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']\n",
    "train=year_transform(train,years_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yBKLIkZBwJw"
   },
   "source": [
    "## Lets get to more modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoLars, Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MSedV15yEQ2"
   },
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(train.drop(columns='SalePrice'), train.SalePrice, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "RaYhJGfzy1ERA",
    "outputId": "aaa366b1-5365-4e3f-ecb9-0ac9bac4391b"
   },
   "outputs": [],
   "source": [
    "log = LinearRegression()\n",
    "log = log.fit(X_train3,y_train3)\n",
    "y_pred3 = log.score(X_test3,y_test3)\n",
    "ttree3 = log.score(X_train3, y_train3)\n",
    "pred3_train = log.predict(X_train3)\n",
    "pred3_test = log.predict(X_test3)\n",
    "print(\"Training score of Tree Model\",ttree3)\n",
    "print(\"Testing Score of Tree Model\",y_pred3)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred3_train,y_train3)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred3_test,y_test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are already doing better!\n",
    "Much closer to out baseline preformer, did our changes effect the baseline as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "JMQLNCoqyEQ8",
    "outputId": "c17d0dcd-4e13-4707-f112-5764d7fd95dd"
   },
   "outputs": [],
   "source": [
    "tree = RandomForestRegressor()\n",
    "tree = tree.fit(X_train3,y_train3)\n",
    "y_pred3 = tree.score(X_test3,y_test3)\n",
    "ttree3 = tree.score(X_train3, y_train3)\n",
    "pred3_trainRF = tree.predict(X_train3)\n",
    "pred3_testRF = tree.predict(X_test3)\n",
    "print(\"Training score of Tree Model\",ttree3)\n",
    "print(\"Testing Score of Tree Model\",y_pred3)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred3_trainRF,y_train3)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred3_testRF,y_test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, up to 90% explained variance. Very cool!\n",
    "What can we do to inspect what is actually going on point-by-point, or how can we improve the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this \"residuals\" stuff? This is a basic test that attempts to uncover if we have left information out of consideration of the model. \n",
    "\n",
    "How? The residuals are the measurements between the predicted scores and the actual scores.\n",
    "\n",
    "If there is a pattern left in those differences, there is a trend missing from our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(10, 12))\n",
    "\n",
    "ax0[0].scatter(pred3_test, y_test3, s=8)\n",
    "ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[0].set_ylabel('True target')\n",
    "ax0[0].set_xlabel('Predicted target')\n",
    "ax0[0].text(s='Linear Regression', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test3, pred3_test), median_absolute_error(y_test3, pred3_test)))\n",
    "ax0[0].set_xlim([0, 7e5])\n",
    "ax0[0].set_ylim([0, 7e5])\n",
    "ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[0].scatter(pred3_test, (pred3_testRF - y_test3), s=8)\n",
    "ax1[0].set_ylabel('Residual')\n",
    "ax1[0].set_xlabel('Predicted target')\n",
    "ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax0[1].scatter(pred_test, y_test3, s=8)\n",
    "ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[1].set_ylabel('True target')\n",
    "ax0[1].set_xlabel('Predicted target')\n",
    "ax0[1].text(s='Random Forest Regression', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test3, pred3_testRF), median_absolute_error(y_test3, pred3_testRF)))\n",
    "ax0[1].set_xlim([0, 7e5])\n",
    "ax0[1].set_ylim([0, 7e5])\n",
    "ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[1].scatter(pred3_testRF, (pred3_testRF - y_test3), s=8)\n",
    "ax1[1].set_ylabel('Residual')\n",
    "ax1[1].set_xlabel('Predicted target')\n",
    "ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "f.suptitle(\"Ames housing data: selling price\", y=0.035)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both look pretty good (as expected) We do see a little droop in the right hand side of the graphs.\n",
    "\n",
    "This means that for the more extreme prices, we are underfitting. What does that remind us on from DDD part_2?\n",
    "\n",
    "TRANSFORMS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something I like to do once I get into heavy duty stuff, is seporate the target from the variables, therefore it is untouched by any transformations, \n",
    "as well as being easily acessed for graphs and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train.pop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.SalePrice  #WILL FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(target, fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(target)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(target, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "target_log = np.log1p(target)\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(target_log, fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(target_log)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(target_log, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our distrobution is much more normal and the Q-Q Plot (the bottom graphs) show how far a distrobution is from normal \n",
    "by fitting it to a straight line. Looks like we are much more on target now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But will that actually help predictions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back_from_log = np.expm1(target_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainL, X_testL, y_trainL, y_testL = train_test_split(train, target_log, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "RaYhJGfzyERA2",
    "outputId": "aaa366b1-5365-4e3f-ecb9-0ac9bac4391b"
   },
   "outputs": [],
   "source": [
    "log3 = LinearRegression()\n",
    "log3 = log3.fit(X_trainL,y_trainL)\n",
    "y_predL = log3.score(X_testL,y_testL)\n",
    "ttreeL = log3.score(X_trainL, y_trainL)\n",
    "predL = log3.predict(X_trainL)\n",
    "predNL = np.expm1(predL)\n",
    "predL_test = log3.predict(X_testL)\n",
    "predNL_test = np.expm1(predL_test)\n",
    "\n",
    "print(\"Training score of Reg Model\",ttreeL)\n",
    "print(\"Testing Score of Reg Model\",y_predL)\n",
    "print(f'\\nTraining RMSE of Reg model: {rmse(predNL,y_trainL)}')\n",
    "print(f'Testing RMSE of Reg model: {rmse(predNL_test,y_testL)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(predNL,y_trainL)}')\n",
    "print(f'Testing MAE of Reg model: {mae(predNL_test,y_testL)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "JMQLNCoqyEQ8",
    "outputId": "c17d0dcd-4e13-4707-f112-5764d7fd95dd"
   },
   "outputs": [],
   "source": [
    "treeL = RandomForestRegressor()\n",
    "treeL = treeL.fit(X_trainL,y_trainL)\n",
    "y_predLF = treeL.score(X_testL,y_testL)\n",
    "ttreeLF = treeL.score(X_trainL, y_trainL)\n",
    "predLF = treeL.predict(X_trainL)\n",
    "predNLF = np.expm1(predLF)\n",
    "predL_testF = treeL.predict(X_testL)\n",
    "predNL_testF = np.expm1(predL_testF)\n",
    "\n",
    "\n",
    "print(\"Training score of Forest Model\",ttreeLF)\n",
    "print(\"Testing Score of Forest Model\",y_predLF)\n",
    "print(f'\\nTraining RMSE of Forest model: {rmse(predNLF,y_trainL)}')\n",
    "print(f'Testing RMSE of Forest model: {rmse(predNL_testF,y_testL)}')\n",
    "print(f'\\nTraining MAE of Forest model: {mae(predNLF,y_trainL)}')\n",
    "print(f'Testing MAE of Forest model: {mae(predNL_testF,y_testL)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have basically flipped the results on their head. Our transformation has hurt the RF model, and has helped the linear model.\n",
    "We always have to make decisions in our DS projects that will have large impacts on our outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = np.expm1(y_testL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(6.5, 8))\n",
    "\n",
    "ax0[0].scatter(predNL_test, tester, s=8)\n",
    "ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[0].set_ylabel('True target')\n",
    "ax0[0].set_xlabel('Predicted target')\n",
    "ax0[0].text(s='Linear Regression', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(tester, predNL_test), median_absolute_error(tester, predNL_test)))\n",
    "ax0[0].set_xlim([0, 7e5])\n",
    "ax0[0].set_ylim([0, 7e5])\n",
    "ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[0].scatter(predNL_test, (predNL_test - tester), s=8)\n",
    "ax1[0].set_ylabel('Residual')\n",
    "ax1[0].set_xlabel('Predicted target')\n",
    "ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax0[1].scatter(predNL_testF, tester, s=8)\n",
    "ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[1].set_ylabel('True target')\n",
    "ax0[1].set_xlabel('Predicted target')\n",
    "ax0[1].text(s='Fandom Forest Regression', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(tester, predNL_testF), median_absolute_error(tester, predNL_testF)))\n",
    "ax0[1].set_xlim([0, 7e5])\n",
    "ax0[1].set_ylim([0, 7e5])\n",
    "ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[1].scatter(predNL_testF, (predNL_testF - tester), s=8)\n",
    "ax1[1].set_ylabel('Residual')\n",
    "ax1[1].set_xlabel('Predicted target')\n",
    "ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "f.suptitle(\"Ames housing data: selling price\", y=0.035)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOK! our residuals are streghtened, and our R^2 is up!\n",
    "\n",
    "We are much more toward the path that we want, even beating our RF algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if we can make a better and simpler model in a different way.\n",
    "\n",
    "We tried only selecting correlated values, and did pretty well, are there other options.\n",
    "\n",
    "We have three major shoices here:\n",
    "\n",
    "1.) Univariate/Filter based Selection -- Choosing features ourselves by how they impact the model in some way (correlation)\n",
    "\n",
    "2.) Wrapper Methods -- Uses one single ML algorithm and uses its performance as evaluation criteria, \n",
    "                        we chooses features based on their influence on preformance. (p-value of feature importance)\n",
    "\n",
    "3.) Embedded Methods -- Repeadedly tries different combinations of features to achieve the best feature set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried #1 before without too much success,\n",
    "So lets build a model with #2, we are going to take out the pvalues of each predictive column,\n",
    "then filter for ones that have impact on the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_trainL.columns\n",
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    columns = np.delete(columns, j)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x, columns\n",
    "\n",
    "SL = 0.02\n",
    "data_modeled, selected_columns = backwardElimination(X_trainL.iloc[:,1:].values, y_trainL.values, SL, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = X_trainL[selected_columns]\n",
    "X_test_s = X_testL[selected_columns]\n",
    "y_train_s = y_trainL\n",
    "y_test_s = y_testL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "fb7JZkQVyEPX",
    "outputId": "47705031-1e68-4f2a-fc20-599e96e56181"
   },
   "outputs": [],
   "source": [
    "#fitting the model to the data\n",
    "reg_s = reg.fit(X_train_s,y_train_s)\n",
    "#Score the results\n",
    "reg = reg.fit(X_train_s,y_train_s)\n",
    "y_pred = reg.score(X_test_s,y_test_s)\n",
    "ttree = reg.score(X_train_s, y_train_s)\n",
    "pred_train = reg.predict(X_train_s)\n",
    "pred = np.expm1(pred_train)\n",
    "pred_test = reg.predict(X_test_s)\n",
    "pret = np.expm1(pred_test)\n",
    "print(\"Training score of Regression Model\",ttree)\n",
    "print(\"Testing Score of Regression Model\",y_pred)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred,y_train_s)}')\n",
    "print(f'Testing RMSE of model: {rmse(pret,y_test_s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for comparisons sake this is the old model with lots of features\n",
    "log3 = LinearRegression()\n",
    "log3 = log3.fit(X_trainL,y_trainL)\n",
    "y_predL = log3.score(X_testL,y_testL)\n",
    "ttreeL = log3.score(X_trainL, y_trainL)\n",
    "predL = log3.predict(X_trainL)\n",
    "predNL = np.expm1(predL)\n",
    "predL_test = log3.predict(X_testL)\n",
    "predNL_test = np.expm1(predL_test)\n",
    "\n",
    "print(\"Training score of Reg Model\",ttreeL)\n",
    "print(\"Testing Score of Reg Model\",y_predL)\n",
    "print(f'\\nTraining RMSE of Reg model: {rmse(predNL,y_trainL)}')\n",
    "print(f'Testing RMSE of Reg model: {rmse(predNL_test,y_testL)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(predNL,y_trainL)}')\n",
    "print(f'Testing MAE of Reg model: {mae(predNL_test,y_testL)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about model size is always important, \n",
    "optimizing to a smaller model usually means more consistant results (less testing error)\n",
    "as well as quicker predictions.\n",
    "\n",
    "Looks like there is a good way to optimize this model fo speed as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning the Model Hyperperameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { \n",
    "    'TTR': TransformedTargetRegressor()}\n",
    "\n",
    "params = {\n",
    "    'TTR': {\n",
    "        'regressor':  [ \n",
    "            LassoLars(alpha=0.001),\n",
    "            LassoLars(alpha=0.01),\n",
    "            LassoLars(alpha=0.1),\n",
    "            LassoLars(alpha=1),\n",
    "            LassoLars(alpha=10),\n",
    "            Ridge(alpha=1),\n",
    "            Ridge(alpha=6),\n",
    "            Ridge(alpha=8),\n",
    "            Ridge(alpha=10),\n",
    "            Ridge(alpha=12),\n",
    "            Ridge(alpha=30),\n",
    "            ElasticNet(alpha=0.001),\n",
    "            ElasticNet(alpha=0.01),\n",
    "            ElasticNet(alpha=0.1),\n",
    "            ElasticNet(alpha=1),\n",
    "            ElasticNet(alpha=10),\n",
    "            ElasticNet(alpha=100),\n",
    "            HuberRegressor(alpha=0.001),\n",
    "            HuberRegressor(alpha=0.01),\n",
    "            HuberRegressor(alpha=0.1),\n",
    "            HuberRegressor(alpha=1),\n",
    "            HuberRegressor(alpha=10),\n",
    "            HuberRegressor(alpha=100)],\n",
    "        'transformer': [QuantileTransformer(n_quantiles=750,output_distribution='normal'),\n",
    "                       QuantileTransformer(n_quantiles=300,output_distribution='normal')]},\n",
    "        'regressor__alpha': [1,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "    \n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, **grid_kwargs):\n",
    "        for key in self.keys:\n",
    "            print('Running GridSearchCV for %s.' % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            grid_search = GridSearchCV(model, params, cv=5, **grid_kwargs)\n",
    "            grid_search.fit(X, y)\n",
    "            self.grid_searches[key] = grid_search\n",
    "        print('Done.')\n",
    "    \n",
    "    def score_summary(self, sort_by='mean_test_score'):\n",
    "        frames = []\n",
    "        for name, grid_search in self.grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            frame = frame.filter(regex='^(?!.*param_).*$')\n",
    "            frame['estimator'] = len(frame)*[name]\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['rank_test_score', 'index'], 1)\n",
    "        \n",
    "        columns = df.columns.tolist()\n",
    "        columns.remove('estimator')\n",
    "        columns = ['estimator']+columns\n",
    "        df = df[columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, params)\n",
    "helper1.fit(X_train_s, y_train_s, scoring='r2', n_jobs=1)\n",
    "helper1.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, params)\n",
    "helper1.fit(X_train3, y_train3, scoring='r2', n_jobs=1)\n",
    "helper1.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After repeated cross validation, our model selection tool shows us two things, one, that Ridge() trasformer is better than our standard LinearRegression,\n",
    "and also, that having more features \"in this case\" helped.\n",
    "Probably why: Ridge Regression actually attempts to limit the number of varables that are allowed to contribute to the model. \n",
    "Therefore, it is limiting the features interally and scoring off that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1.score_summary().params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans3 = TransformedTargetRegressor(\n",
    "    regressor= ElasticNet(alpha=0.001),\n",
    "    transformer=QuantileTransformer(n_quantiles=750,\n",
    "                                    output_distribution='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans = TransformedTargetRegressor(\n",
    "    regressor= Ridge(alpha=8),\n",
    "    transformer=QuantileTransformer(n_quantiles=750,\n",
    "                                    output_distribution='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans3 = regr_trans3.fit(X_train3,y_train3)\n",
    "y_pred = regr_trans3.score(X_test3,y_test3)\n",
    "ttree = regr_trans3.score(X_train3, y_train3)\n",
    "pred_train = regr_trans3.predict(X_train3)\n",
    "pred_test = regr_trans3.predict(X_test3)\n",
    "print(\"Training score of Tree Model\",y_pred)\n",
    "print(\"Testing Score of Tree Model\",ttree)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_train,y_train3)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_test,y_test3)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(pred_train,y_train3)}')\n",
    "print(f'Testing MAE of Reg model: {mae(pred_test,y_test3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans = regr_trans.fit(X_train3,y_train3)\n",
    "y_pred = regr_trans.score(X_test3,y_test3)\n",
    "ttree = regr_trans.score(X_train3, y_train3)\n",
    "pred_train = regr_trans.predict(X_train3)\n",
    "pred_test = regr_trans.predict(X_test3)\n",
    "print(\"Training score of Tree Model\",y_pred)\n",
    "print(\"Testing Score of Tree Model\",ttree)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_train,y_train3)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_test,y_test3)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(pred_train,y_train3)}')\n",
    "print(f'Testing MAE of Reg model: {mae(pred_test,y_test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So awesome! Let's save this for later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(regr_trans, open('FinalModel.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FinalModel.sav', \"rb\") as f:\n",
    "        SavedModel = pickle.load(f)\n",
    "did_I_save=SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fil_zero(df):\n",
    "    df['GarageYrBlt']=df['GarageYrBlt'].fillna(0)\n",
    "    df['MasVnrArea']=df['MasVnrArea'].fillna(0)\n",
    "    df['LotFrontage']=df['LotFrontage'].fillna(0)\n",
    "    df['MasVnrType']=df['MasVnrType'].fillna(\"None\")\n",
    "    return df\n",
    "\n",
    "def fix_cat_feat(df):\n",
    "    df['Alley']=df['Alley'].apply(lambda x: 1 if x!=0 else 0)\n",
    "    df['LotShape']=df['LotShape'].apply(lambda x: 1 if x=='Reg' or x=='IR1' else 0)\n",
    "    df['LandContour']=df['LandContour'].apply(lambda x: 1 if x=='Lvl' else 0)\n",
    "    df['Utilities']=df['Utilities'].apply(lambda x: 1 if x=='AllPub' or x=='NoSewr' else 0)\n",
    "    df['LotConfig']=df['LotConfig'].apply(lambda x: 1 if x=='Inside' or x=='CulDSac' else 0)\n",
    "    df['LotConfig']=df['LotConfig'].apply(lambda x: 1 if x=='Inside' or x=='CulDSac' else 0)\n",
    "\n",
    "    df['LandSlope']=df['LandSlope'].apply(lambda x: 1 if x=='Gtl' else 0)\n",
    "    df['ExterQual']=df['ExterQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "    df['ExterCond']=df['ExterCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "    df['BsmtQual']=df['BsmtQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['BsmtCond']=df['BsmtCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['BsmtExposure']=df['BsmtExposure'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['BsmtFinType1']=df['BsmtFinType1'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "    df['BsmtFinType2']=df['BsmtFinType2'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "    df['HeatingQC']=df['HeatingQC'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['CentralAir']=df['CentralAir'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "    df['KitchenQual']=df['KitchenQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else 1))))\n",
    "    df['Functional']=df['Functional'].apply(lambda x: 5 if x=='GLQ' else (4 if x=='ALQ' else (3 if x=='BLQ' else (2 if x=='Rec' else (1 if x=='LwQ' else 0)))))\n",
    "    df['TOT_bath']=df['FullBath']+(.5*df['HalfBath'])\n",
    "    df['FireplaceQu']=df['FireplaceQu'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['GarageFinish']=df['GarageFinish'].apply(lambda x: 3 if x=='Fin' else (2 if x=='RFn' else (1 if x=='Unf' else 0)))\n",
    "    df['GarageQual']=df['GarageQual'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['GarageCond']=df['GarageCond'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['PavedDrive']=df['PavedDrive'].apply(lambda x: 1 if x=='Y' or x=='P' else 0)\n",
    "    df['PoolQC']=df['PoolQC'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    df['Fence']=df['Fence'].apply(lambda x: 5 if x=='Ex' else (4 if x=='Gd' else (3 if x=='TA' else (2 if x=='Fa' else (1 if x=='Po' else 0)))))\n",
    "    return df\n",
    "\n",
    "def fix_dummies(df):\n",
    "    df=pd.concat([df,pd.get_dummies(df.MSZoning)],axis=1)\n",
    "    df.drop(columns=('MSZoning'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.MSSubClass)],axis=1)\n",
    "    df.drop(columns=('MSSubClass'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.Neighborhood)],axis=1)\n",
    "    df.drop(columns=('Neighborhood'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.BldgType)],axis=1)\n",
    "    df.drop(columns=('BldgType'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.HouseStyle)],axis=1)\n",
    "    df.drop(columns=('HouseStyle'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.GarageType)],axis=1)\n",
    "    df.drop(columns=('GarageType'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.SaleCondition)],axis=1)\n",
    "    df.drop(columns=('SaleCondition'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.SaleType)],axis=1)\n",
    "    df.drop(columns=('SaleType'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.Condition1)],axis=1)\n",
    "    df.drop(columns=('Condition1'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.MasVnrType)],axis=1)\n",
    "    df.drop(columns=('MasVnrType'),inplace=True)\n",
    "\n",
    "    df=pd.concat([df,pd.get_dummies(df.Foundation)],axis=1)\n",
    "    df.drop(columns=('Foundation'),inplace=True)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df=df.drop(columns=['Id','Street','Condition2','RoofStyle','RoofMatl','Exterior1st','Exterior2nd', 'Heating',\n",
    "                              'Electrical','MiscFeature'])\n",
    "    return df\n",
    "\n",
    "def years_transform(df):\n",
    "    for column in ['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']:\n",
    "        df[column]=df[column]-(df[column].min()-1)\n",
    "        df[column]=df[column].apply(lambda x: 0 if x==0 else np.log10(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ChristianRLynn/DataSets/main/train.csv'\n",
    "raw = pd.read_csv(url, error_bad_lines=False); raw.drop(columns='SalePrice',inplace=True)\n",
    "\n",
    "first = fil_zero(raw)\n",
    "\n",
    "second = fix_cat_feat(first)\n",
    "\n",
    "third = fix_dummies(second)\n",
    "\n",
    "fourth = years_transform(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FinalModel.sav', \"rb\") as f:\n",
    "        SavedModel = pickle.load(f)\n",
    "did_I_save=SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_save.predict(third)[1:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's All Folks! We have a model saved!\n",
    "## Trughfully there is a lot to discuss about creating model pipelines and model deployment,\n",
    "## but, so little time, so much fun left. \n",
    "THANKS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra FUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY8sDviWyERP"
   },
   "outputs": [],
   "source": [
    "log_col_list=['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2',\n",
    "              'BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF',\n",
    "              'GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "              'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea']\n",
    "train2=log_trans(train,log_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DE7Ey9W2yERU"
   },
   "outputs": [],
   "source": [
    "years_column=['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']\n",
    "train2=year_transform(train2,years_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aavp5ux4yERX",
    "outputId": "1510ec25-4ab7-4069-dd6d-ef433c81b9e2"
   },
   "outputs": [],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "868isjQDyERk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "train3=scaler.fit_transform(train2)\n",
    "train3=pd.DataFrame(data=train3,    # values\n",
    "              index=train2.index,    # 1st column as index\n",
    "              columns=train2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XHq4lupzyERp",
    "outputId": "f2cfbd06-9d11-422f-c07e-c75c04cb715b"
   },
   "outputs": [],
   "source": [
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGhnW_9lyER0"
   },
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(train3, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4l, X_test4l, y_train4l, y_test4l = train_test_split(train3, target_log, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "rHyki8g5yER5",
    "outputId": "b6aad918-ff64-467e-dded-d4bf61ff566d"
   },
   "outputs": [],
   "source": [
    "tree = RandomForestRegressor()\n",
    "tree = tree.fit(X_train4,y_train4)\n",
    "y_pred4 = tree.score(X_test4,y_test4)\n",
    "ttree4 = tree.score(X_train4, y_train4)\n",
    "pred4_train = tree.predict(X_train4)\n",
    "pred4_test = tree.predict(X_test4)\n",
    "print(\"Training score of Tree Model\",ttree4)\n",
    "print(\"Testing Score of Tree Model\",y_pred4)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred4_train,y_train4)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred4_test,y_test4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treel = RandomForestRegressor()\n",
    "treel = treel.fit(X_train4l,y_train4l)\n",
    "y_pred4l = treel.score(X_test4l,y_test4l)\n",
    "ttree4l = treel.score(X_train4l, y_train4l)\n",
    "pred4_trainl = tree.predict(X_train4l)\n",
    "pred4_testl = tree.predict(X_test4l)\n",
    "print(\"Training score of Tree Model\",ttree4)\n",
    "print(\"Testing Score of Tree Model\",y_pred4)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred4_trainl,y_train4l)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred4_testl,y_test4l)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(6.5, 8))\n",
    "\n",
    "regr = RidgeCV()\n",
    "regr.fit(X_train4, y_train4)\n",
    "y_pred = regr.predict(X_test4)\n",
    "\n",
    "ax0[0].scatter(y_pred, y_test4, s=8)\n",
    "ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[0].set_ylabel('True target')\n",
    "ax0[0].set_xlabel('Predicted target')\n",
    "ax0[0].text(s='Ridge regression \\n without target transformation', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test4, y_pred), median_absolute_error(y_test4, y_pred)))\n",
    "ax0[0].set_xlim([0, 7e5])\n",
    "ax0[0].set_ylim([0, 7e5])\n",
    "ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[0].scatter(y_pred, (y_pred - y_test4), s=8)\n",
    "ax1[0].set_ylabel('Residual')\n",
    "ax1[0].set_xlabel('Predicted target')\n",
    "ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "regr_trans = TransformedTargetRegressor(\n",
    "    regressor=RidgeCV(),\n",
    "    transformer=QuantileTransformer(n_quantiles=900,\n",
    "                                    output_distribution='normal'))\n",
    "regr_trans.fit(X_train4, y_train4)\n",
    "y_pred = regr_trans.predict(X_test4)\n",
    "\n",
    "ax0[1].scatter(y_pred, y_test4, s=8)\n",
    "ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[1].set_ylabel('True target')\n",
    "ax0[1].set_xlabel('Predicted target')\n",
    "ax0[1].text(s='Ridge regression \\n with target transformation', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test4, y_pred), median_absolute_error(y_test4, y_pred)))\n",
    "ax0[1].set_xlim([0, 7e5])\n",
    "ax0[1].set_ylim([0, 7e5])\n",
    "ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[1].scatter(y_pred, (y_pred - y_test4), s=8)\n",
    "ax1[1].set_ylabel('Residual')\n",
    "ax1[1].set_xlabel('Predicted target')\n",
    "ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "f.suptitle(\"Ames housing data: selling price\", y=0.035)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(2, 2, sharey='row', figsize=(6.5, 8))\n",
    "\n",
    "regr = TransformedTargetRegressor(\n",
    "    regressor=RidgeCV(),\n",
    "    transformer=QuantileTransformer(n_quantiles=900,\n",
    "                                    output_distribution='normal'))\n",
    "regr.fit(X_train4, y_train4)\n",
    "y_pred = regr.predict(X_test4)\n",
    "\n",
    "ax0[0].scatter(y_pred, y_test4, s=8)\n",
    "ax0[0].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[0].set_ylabel('True target')\n",
    "ax0[0].set_xlabel('Predicted target')\n",
    "ax0[0].text(s='Ridge regression \\n with target transformation', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[0].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test4, y_pred), median_absolute_error(y_test4, y_pred)))\n",
    "ax0[0].set_xlim([0, 7e5])\n",
    "ax0[0].set_ylim([0, 7e5])\n",
    "ax0[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[0].scatter(y_pred, (y_pred - y_test4), s=8)\n",
    "ax1[0].set_ylabel('Residual')\n",
    "ax1[0].set_xlabel('Predicted target')\n",
    "ax1[0].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "regr_trans = TransformedTargetRegressor(\n",
    "    regressor= RandomForestRegressor(bootstrap='False',criterion='mae',max_depth=12,max_features=20,min_samples_split=2,n_estimators= 200),\n",
    "    transformer=QuantileTransformer(n_quantiles=900,\n",
    "                                    output_distribution='normal'))\n",
    "regr_trans.fit(X_train4, y_train4)\n",
    "y_pred = regr_trans.predict(X_test4)\n",
    "\n",
    "ax0[1].scatter(y_pred, y_test4, s=8)\n",
    "ax0[1].plot([0, 7e5], [0, 7e5], '--k')\n",
    "ax0[1].set_ylabel('True target')\n",
    "ax0[1].set_xlabel('Predicted target')\n",
    "ax0[1].text(s='RF regression \\n with target transformation', x=-5e4,\n",
    "            y=8e5, fontsize=12, multialignment='center')\n",
    "ax0[1].text(3e4, 64e4, r'$R^2$=%.2f, MAE=%.2f' % (\n",
    "    r2_score(y_test4, y_pred), median_absolute_error(y_test4, y_pred)))\n",
    "ax0[1].set_xlim([0, 7e5])\n",
    "ax0[1].set_ylim([0, 7e5])\n",
    "ax0[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "ax1[1].scatter(y_pred, (y_pred - y_test4), s=8)\n",
    "ax1[1].set_ylabel('Residual')\n",
    "ax1[1].set_xlabel('Predicted target')\n",
    "ax1[1].ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "\n",
    "f.suptitle(\"Ames housing data: selling price\", y=0.035)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Feature Engineering actually do much??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_engineering(df):\n",
    "    df[\"porch_tot\"]=df['EnclosedPorch']+df['3SsnPorch']+df['ScreenPorch']+df['WoodDeckSF']+df['OpenPorchSF']\n",
    "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "    df['base_bath_tot'] = df['BsmtFullBath'] + (df['BsmtFullBath']*.5)\n",
    "    df['rooms_tot'] = df['TotalBsmtSF']/100 + df['TotRmsAbvGrd'] + df['base_bath_tot']\n",
    "    df['sqr_ft_per_room'] = df['TotalSF']/df['rooms_tot']\n",
    "    df[\"quality_add\"]=df['KitchenQual']+df['GarageQual']+df['FireplaceQu']+df['HeatingQC']+df['BsmtQual']+df['ExterQual']+df['OverallQual']\n",
    "    df[\"condition_add\"]=df['KitchenQual']+df['GarageCond']+df['HeatingQC']+df['BsmtCond']+df['ExterCond']+df['OverallCond']\n",
    "    df['metrics_add'] = df['condition_add']+df['quality_add']\n",
    "    df[\"quality_add\"]=df['KitchenQual']+df['GarageQual']+df['FireplaceQu']+df['HeatingQC']+df['BsmtQual']+df['ExterQual']+df['OverallQual']\n",
    "    df[\"quality_mult\"]=df['KitchenQual']*2 + df['GarageCond']*df['GarageQual'] + 2*df['HeatingQC']+df['BsmtQual']*df['BsmtCond']+df['ExterQual']*df['ExterCond']+df['OverallCond']*df['OverallQual']*2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=feat_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(tt, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { \n",
    "    'TTR': TransformedTargetRegressor()}\n",
    "\n",
    "params_closer = {\n",
    "    'TTR': {\n",
    "        'regressor':  [ \n",
    "            Ridge(alpha=6),\n",
    "            Ridge(alpha=7),\n",
    "            Ridge(alpha=8),\n",
    "            Ridge(alpha=9),\n",
    "            Ridge(alpha=10),\n",
    "            Ridge(alpha=11),\n",
    "            Ridge(alpha=12),\n",
    "            Ridge(alpha=13),\n",
    "            Ridge(alpha=14),\n",
    "            Ridge(alpha=15),\n",
    "            Ridge(alpha=16),\n",
    "            ElasticNet(alpha=0.01),\n",
    "            ElasticNet(alpha=0.1),\n",
    "            ElasticNet(alpha=1),\n",
    "            ElasticNet(alpha=10),\n",
    "            HuberRegressor(alpha=0.01),\n",
    "            HuberRegressor(alpha=0.1),\n",
    "            HuberRegressor(alpha=1),\n",
    "            HuberRegressor(alpha=10)],\n",
    "        'transformer': [QuantileTransformer(n_quantiles=750,output_distribution='normal')]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, params_closer)\n",
    "helper1.fit(X_train_full, y_train_full, scoring='r2', n_jobs=1)\n",
    "helper1.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1.score_summary().params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans_full = TransformedTargetRegressor(\n",
    "    regressor= Ridge(alpha=9),\n",
    "    transformer=QuantileTransformer(n_quantiles=750,\n",
    "                                    output_distribution='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_trans_full = regr_trans_full.fit(X_train_full,y_train_full)\n",
    "y_pred = regr_trans_full.score(X_test_full,y_test_full)\n",
    "ttree = regr_trans_full.score(X_train_full, y_train_full)\n",
    "pred_train = regr_trans_full.predict(X_train_full)\n",
    "pred_test = regr_trans_full.predict(X_test_full)\n",
    "print(\"Training score of Tree Model\",y_pred)\n",
    "print(\"Testing Score of Tree Model\",ttree)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_train,y_train_full)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_test,y_test_full)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(pred_train,y_train_full)}')\n",
    "print(f'Testing MAE of Reg model: {mae(pred_test,y_test_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something I have been working on and very interested in ius GeneticSelection Algorithms\n",
    "They offer a good chance of automating difficult parts of modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5MQAGPhyESR"
   },
   "outputs": [],
   "source": [
    "!pip install genetic_selection\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "# create the GeneticSelection search with the different parameters available.\n",
    "selection = GeneticSelectionCV(regr_trans_full,\n",
    "                              cv=5,\n",
    "                              scoring=\"r2\",\n",
    "                              max_features=20,\n",
    "                              n_population=120,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=50,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              n_gen_no_change=10,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "# fit the GA search to our data.\n",
    "selection = selection.fit(X_train_full, y_train_full)\n",
    "\n",
    "# print the results.\n",
    "print(selection.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsies=tt.loc[:, selection.support_ == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_t, y, y_t = train_test_split(newsies, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for comparisons sake this is the old baseline model with few features\n",
    "log3 = LinearRegression()\n",
    "log3 = log3.fit(X,y)\n",
    "y_predL = log3.score(X_t,y_t)\n",
    "ttreeL = log3.score(X, y)\n",
    "predL = log3.predict(X)\n",
    "#predNL = np.expm1(predL)\n",
    "predL_test = log3.predict(X_t)\n",
    "#predNL_test = np.expm1(predL_test)\n",
    "\n",
    "print(\"Training score of Reg Model\",ttreeL)\n",
    "print(\"Testing Score of Reg Model\",y_predL)\n",
    "print(f'\\nTraining RMSE of Reg model: {rmse(predL,y)}')\n",
    "print(f'Testing RMSE of Reg model: {rmse(predL_test,y_t)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(predL,y)}')\n",
    "print(f'Testing MAE of Reg model: {mae(predL_test,y_t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper11 = EstimatorSelectionHelper(models, params_closer)\n",
    "helper11.fit(X, y, scoring='r2', n_jobs=1)\n",
    "helper11.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijUEUFcqyESY"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas=[0.001, 0.1, 2, 4, 6, 8, 10, 12, 14, 50]\n",
    "\n",
    "models3 = { \n",
    "    'Linear': LinearRegression(),\n",
    "    'Lars': LassoLars(),\n",
    "    'RFReg': RandomForestRegressor(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'EN': ElasticNet(),\n",
    "    'Huber': HuberRegressor()}\n",
    "\n",
    "params3 = {\n",
    "    'Linear':  {\n",
    "        'normalize': ['True', 'False']},\n",
    "    'Lars': {\n",
    "        'fit_intercept': ['True'],\n",
    "        'normalize': ['True', 'False'],\n",
    "        'alpha': alphas,\n",
    "        'eps': [0,10,20,30,40,50,60,70]},\n",
    "    'RFReg': {\n",
    "        'n_estimators': [30, 60, 90],\n",
    "        'criterion': ['mse', 'mae'],\n",
    "        'max_depth': [6, 12],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'max_features': [3,7,10,'n_features'],\n",
    "        'bootstrap': ['False']},\n",
    "    'Lasso': {\n",
    "        'alpha': [.5,1.0,2,10],\n",
    "        'fit_intercept': ['False'],\n",
    "        'normalize': ['False', 'True'],\n",
    "        'max_iter': [50,500,1000,5000]},\n",
    "    'Ridge': {\"alpha\": alphas},\n",
    "    'EN': {\n",
    "        'alpha': alphas,\n",
    "        'l1_ratio': [0.25, 0.5, 0.75]},\n",
    "    'Huber': {\n",
    "        'alpha': alphas, \n",
    "        'epsilon': [1,1.35,1.9]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper11.score_summary().params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ZUYGQRF2yESf",
    "outputId": "c67f4f86-2ccf-4f7b-a2c3-8802c3016672"
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models3, params3)\n",
    "helper1.fit(X_train3, y_train3, scoring='r2', n_jobs=1)\n",
    "helper1.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, params_closer)\n",
    "helper1.fit(X, y, scoring='r2', n_jobs=1)\n",
    "helper1.score_summary().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "RlO6xRHwyETD",
    "outputId": "7f6ec287-551f-4478-a639-7c2dcf5dac86"
   },
   "outputs": [],
   "source": [
    "helper1.score_summary().params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = TransformedTargetRegressor(\n",
    "                                regressor= Ridge(alpha=6),\n",
    "                                transformer=QuantileTransformer(n_quantiles=750,\n",
    "                                output_distribution='normal'))\n",
    "best_fit2 = LassoLars(alpha = 10, eps = 0, fit_intercept = True, normalize = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_choice = best_fit\n",
    "cs_choice = cs_choice.fit(X,y)\n",
    "y_pred_cv_test = cs_choice.score(X_t,y_t)\n",
    "y_pred_cv_train = cs_choice.score(X, y)\n",
    "pred_cv_train = cs_choice.predict(X)\n",
    "pred_cv_test = cs_choice.predict(X_t)\n",
    "print(\"Training score of Model\",y_pred_cv_train)\n",
    "print(\"Testing Score of Model\",y_pred_cv_test)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_cv_train,y)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_cv_test,y_t)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(pred_cv_train,y)}')\n",
    "print(f'Testing MAE of Reg model: {mae(pred_cv_test,y_t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_choice = best_fit2\n",
    "cs_choice = cs_choice.fit(X,y)\n",
    "y_pred_cv_test = cs_choice.score(X_t,y_t)\n",
    "y_pred_cv_train = cs_choice.score(X, y)\n",
    "pred_cv_train = cs_choice.predict(X)\n",
    "pred_cv_test = cs_choice.predict(X_t)\n",
    "print(\"Training score of Model\",y_pred_cv_train)\n",
    "print(\"Testing Score of Model\",y_pred_cv_test)\n",
    "print(f'\\nTraining RMSE of model: {rmse(pred_cv_train,y)}')\n",
    "print(f'Testing RMSE of model: {rmse(pred_cv_test,y_t)}')\n",
    "print(f'\\nTraining MAE of Reg model: {mae(pred_cv_train,y)}')\n",
    "print(f'Testing MAE of Reg model: {mae(pred_cv_test,y_t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2Ixj9L-cOyho"
   ],
   "name": "Notebooks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
